{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIE-Project B || Group - 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.signal import resample, find_peaks\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# from sklearn import preprocessing ##importing for normalization\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.preprocessing import MinMaxScaler, minmax_scale, StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import Tensor\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv1D, MaxPooling1D, \\\n",
    "                         AveragePooling1D, GlobalAveragePooling1D, \\\n",
    "                         Add, BatchNormalization, ReLU, Input\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "from keras_tuner.engine.hyperparameters import HyperParameters\n",
    "\n",
    "# plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams['legend.frameon'] = True\n",
    "# plt.rcParams['figure.figsize'] = (8, 8)\n",
    "%matplotlib widget\n",
    "# %matplotlib inline\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get the root directory and change to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = os.getcwd()\n",
    "os.chdir(rootdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Folder Variables Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Names of the folders\n",
    "Training_Folder = 'EPOT_DATA'\n",
    "Validation_Aug_Folder = 'Validation_augmented_data'\n",
    "Experiment = 'Experiment_Data_Group7'\n",
    "Ex_Validation = 'Experimental_validation'\n",
    "\n",
    "counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parse training and validation-augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists for training and validation\n",
    "training_tr = []; training_tr_labels = []\n",
    "\n",
    "validation_aug = []; validation_aug_labels = [] # validation augmented data\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    \n",
    "    if Training_Folder.lower() in subdir.lower():\n",
    "        for file in files:\n",
    "            if file.endswith('.mat'):\n",
    "                lbl = [file.split('_')[1], file.split('_')[2][:3]]\n",
    "                lb = np.asarray(lbl, dtype=float)\n",
    "                # load mat-file\n",
    "                mat = loadmat(os.path.join(subdir, file))\n",
    "                # get the numpy data from the mat file\n",
    "                mat = mat['num_data']\n",
    "                # append data to the list\n",
    "                training_tr.append(mat)\n",
    "                training_tr_labels.append(lb)\n",
    "\n",
    "    elif Validation_Aug_Folder.lower() in subdir.lower():\n",
    "        for file in files:\n",
    "            if file.endswith('.mat'):\n",
    "                lbl = [file.split('_')[1], file.split('_')[2][:3]]\n",
    "                lb = np.asarray(lbl, dtype=float)\n",
    "                # load mat-file\n",
    "                mat = loadmat(os.path.join(subdir, file))\n",
    "                # get the numpy data from the mat file\n",
    "                mat = mat['num_data']\n",
    "                # append data to the list\n",
    "                validation_aug.append(mat)\n",
    "                validation_aug_labels.append(lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "fig, axs = plt.subplots(2, 2, sharex=True, sharey=True)\n",
    "\n",
    "l = 6\n",
    "\n",
    "fig.suptitle(f'EPOT Training Data - {training_tr_labels[l]}')\n",
    "\n",
    "axs[0,0].plot(training_tr[l][:,0], training_tr[l][:,1], label='P - 1', c = 'r')\n",
    "axs[0,1].plot(training_tr[l][:,0], training_tr[l][:,2], label='P - 2', c = 'g')\n",
    "axs[1,0].plot(training_tr[l][:,0], training_tr[l][:,3], label='P - 3', c = 'b')\n",
    "axs[1,1].plot(training_tr[l][:,0], training_tr[l][:,4], label='P - 4', c = 'y')\n",
    "\n",
    "fig.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parse, Cut, Normalize, and Resample the experimental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists for training and validation\n",
    "ex_data = []; ex_labels = []\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    \n",
    "    if Experiment.lower() in subdir.lower():\n",
    "        for file in files:\n",
    "            if file.endswith('.txt'):\n",
    "                \n",
    "                with open(os.path.join(subdir, file), 'r') as f:\n",
    "                    x = pd.read_csv(os.path.join(subdir, file), delimiter='\\t', decimal=',', skiprows=8, header=None)\n",
    "                    x = np.asarray(x, dtype=float)\n",
    "                    ex_data.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "l = 5\n",
    "plt.plot(ex_data[l][:,0], ex_data[l][:,1], label='P - 1', c = 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_cut_data = []\n",
    "for i in range(len(ex_data)):\n",
    "    \n",
    "    threshold = 0.1\n",
    "\n",
    "    x = np.where(abs(ex_data[i][:,1])>threshold)[0][0]\n",
    "    y = np.where(abs(ex_data[i][:,2])>threshold)[0][0]\n",
    "    z = np.where(abs(ex_data[i][:,3])>threshold)[0][0]\n",
    "    p = np.where(abs(ex_data[i][:,4])>threshold)[0][0]\n",
    "\n",
    "    start = min(x,y,z,p)\n",
    "    end = start+200\n",
    "\n",
    "    d = np.empty_like(ex_data[i][start:end,:])\n",
    "\n",
    "    d[:,0] = ex_data[i][start:end, 0]\n",
    "    d[:,1] = (-1)*ex_data[i][start:end, 1]\n",
    "    d[:,2] = (-1)*ex_data[i][start:end, 2]\n",
    "    d[:,3] = (-1)*ex_data[i][start:end, 4]\n",
    "    d[:,4] = (-1)*ex_data[i][start:end, 3]\n",
    "\n",
    "    ex_cut_data.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "l = 5\n",
    "plt.plot(ex_cut_data[l][:,0], ex_cut_data[l][:,1], label='P - 1')\n",
    "plt.plot(ex_cut_data[l][:,0], ex_cut_data[l][:,2], label='P - 2')\n",
    "plt.plot(ex_cut_data[l][:,0], ex_cut_data[l][:,3], label='P - 3')\n",
    "plt.plot(ex_cut_data[l][:,0], ex_cut_data[l][:,4], label='P - 4')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize and Resample experimental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create variables for normalized data\n",
    "ex_norm = np.zeros_like(np.asarray(ex_cut_data))\n",
    "\n",
    "for i in range (0, len(ex_cut_data)):\n",
    "    for j in range (1, 5):\n",
    "        ex_norm[i][:,j] = minmax_scale(ex_cut_data[i][:,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_resample = []\n",
    "\n",
    "# create a dataframe from the normalized data\n",
    "for i in range (0, len(ex_norm)):\n",
    "    ex_resample.append(pd.DataFrame(ex_norm[i], columns = ['time', '1', '2', '3', '4']))\n",
    "    # drop the time column\n",
    "    ex_resample[i] = ex_resample[i].drop(columns = ['time'])\n",
    "\n",
    "size = 100\n",
    "\n",
    "for i in range (0, len(ex_resample)):\n",
    "    ex_resample[i] = resample(ex_resample[i], size)\n",
    "\n",
    "np.asarray(ex_resample).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parse, Cut, Normalize, and Resample the experimental validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists for training and validation\n",
    "ex_val_data = []; ex_val_labels = []\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    \n",
    "    if Ex_Validation.lower() in subdir.lower():\n",
    "        for file in files:\n",
    "            if file.endswith('.txt'):\n",
    "                \n",
    "                with open(os.path.join(subdir, file), 'r') as f:\n",
    "                    # print(file.split('_')[2], file.split('_')[3], file.split('_')[5][:3])\n",
    "                    lbl = [file.split('_')[2], file.split('_')[3], file.split('_')[5][:3]]\n",
    "                    lb = np.asarray(lbl, dtype=float)\n",
    "\n",
    "                    x = pd.read_csv(os.path.join(subdir, file), delimiter='\\t', decimal=',', skiprows=8, header=None)\n",
    "                    x = np.asarray(x, dtype=float)\n",
    "                    ex_val_data.append(x)\n",
    "                    ex_val_labels.append(lb)\n",
    "\n",
    "\n",
    "ex_val_trails = np.asarray(ex_val_labels)[:,2]\n",
    "ex_val_labels = np.delete(ex_val_labels, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex_val_cut_data=[]\n",
    "# for i in range(0,len(ex_val_data)):\n",
    "#     data=ex_data[i][:,0]\n",
    "    \n",
    "#     start_time = 0.04996\n",
    "#     end_time = 0.05016\n",
    "#     start=np.where(data==(start_time))\n",
    "#     end = np.where(data==(end_time))\n",
    "    \n",
    "#     d = np.zeros(((start[0][0]+200-start[0][0]),5))\n",
    "\n",
    "#     d[:,0]=ex_val_data[i][start[0][0]:start[0][0]+200,0]\n",
    "#     d[:,1]=ex_val_data[i][start[0][0]:start[0][0]+200,1]\n",
    "#     d[:,2]=ex_val_data[i][start[0][0]:start[0][0]+200,2]\n",
    "#     d[:,3]=ex_val_data[i][start[0][0]:start[0][0]+200,4]\n",
    "#     d[:,4]=ex_val_data[i][start[0][0]:start[0][0]+200,3]\n",
    "    \n",
    "#     ex_val_cut_data.append(d)\n",
    "#----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "ex_val_cut_data = []\n",
    "for i in range(len(ex_val_data)):\n",
    "    \n",
    "    threshold = 0.1\n",
    "\n",
    "    x = np.where(abs(ex_val_data[i][:,1])>threshold)[0][0]\n",
    "    y = np.where(abs(ex_val_data[i][:,2])>threshold)[0][0]\n",
    "    z = np.where(abs(ex_val_data[i][:,3])>threshold)[0][0]\n",
    "    p = np.where(abs(ex_val_data[i][:,4])>threshold)[0][0]\n",
    "\n",
    "    start = min(x,y,z,p)\n",
    "    end = start+180\n",
    "\n",
    "    d = np.empty_like(ex_val_data[i][start:end,:])\n",
    "\n",
    "    d[:,0] = ex_val_data[i][start:end, 0]\n",
    "    d[:,1] = (-1)*ex_val_data[i][start:end, 1]\n",
    "    d[:,2] = (-1)*ex_val_data[i][start:end, 2]\n",
    "    d[:,3] = (-1)*ex_val_data[i][start:end, 4]\n",
    "    d[:,4] = (-1)*ex_val_data[i][start:end, 3]\n",
    "\n",
    "    ex_val_cut_data.append(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize and Resample experimental validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create variables for normalized data\n",
    "ex_val_norm = np.zeros_like(np.asarray(ex_val_cut_data)); ex_val_norm_labels = np.zeros_like(np.asarray(ex_val_cut_data))\n",
    "\n",
    "for i in range (0, len(ex_val_cut_data)):\n",
    "    for j in range (1, 5):\n",
    "        ex_val_norm[i][:,j] = minmax_scale(ex_val_cut_data[i][:,j])\n",
    "\n",
    "scalar = MinMaxScaler()\n",
    "ex_val_norm_labels = scalar.fit_transform(ex_val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_val_resample = []\n",
    "\n",
    "# create a dataframe from the normalized data\n",
    "for i in range (0, len(ex_val_norm)):\n",
    "    ex_val_resample.append(pd.DataFrame(ex_val_norm[i], columns = ['time', '1', '2', '3', '4']))\n",
    "    # drop the time column\n",
    "    ex_val_resample[i] = ex_val_resample[i].drop(columns = ['time'])\n",
    "\n",
    "size = 100\n",
    "\n",
    "for i in range (0, len(ex_val_resample)):\n",
    "    ex_val_resample[i] = resample(ex_val_resample[i], size)\n",
    "\n",
    "np.asarray(ex_val_resample).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Variable initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -----------------------------------------------------------------------------\n",
    "#Assuming P1 on top and counter clockwise order\n",
    "## -----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Variables for the augmented data\n",
    "training_tl = np.zeros_like(np.asarray(training_tr)); training_tl_labels = np.zeros_like(np.asarray(training_tr_labels))\n",
    "training_bl = np.zeros_like(np.asarray(training_tr)); training_bl_labels = np.zeros_like(np.asarray(training_tr_labels))\n",
    "training_br = np.zeros_like(np.asarray(training_tr)); training_br_labels = np.zeros_like(np.asarray(training_tr_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Top-Left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0, len(training_tr)):\n",
    "        training_tl[i][:,0] = training_tr[i][:,0]\n",
    "        training_tl[i][:,1] = training_tr[i][:,1]\n",
    "        training_tl[i][:,2] = training_tr[i][:,4]\n",
    "        training_tl[i][:,3] = training_tr[i][:,3]\n",
    "        training_tl[i][:,4] = training_tr[i][:,2]\n",
    "\n",
    "for i in range (0, len(training_tl_labels)):\n",
    "    training_tl_labels[i][0] = 500 - training_tr_labels[i][0]\n",
    "    training_tl_labels[i][1] = training_tr_labels[i][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bottom-Left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0, len(training_bl)):\n",
    "    training_bl[i][:,0] = training_tl[i][:,0]\n",
    "    training_bl[i][:,1] = training_tl[i][:,3]\n",
    "    training_bl[i][:,2] = training_tl[i][:,2]\n",
    "    training_bl[i][:,3] = training_tl[i][:,1]\n",
    "    training_bl[i][:,4] = training_tl[i][:,4]\n",
    "\n",
    "for i in range (0, len(training_bl_labels)):\n",
    "    training_bl_labels[i][0] = 500. - training_tr_labels[i][0]\n",
    "    training_bl_labels[i][1] = 500. - training_tr_labels[i][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bottom-Right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0, len(training_br)):\n",
    "        training_br[i][:,0] = training_bl[i][:,0]\n",
    "        training_br[i][:,1] = training_bl[i][:,1]\n",
    "        training_br[i][:,2] = training_bl[i][:,4]\n",
    "        training_br[i][:,3] = training_bl[i][:,3]\n",
    "        training_br[i][:,4] = training_bl[i][:,2]\n",
    "\n",
    "for i in range (0, len(training_br_labels)):\n",
    "    training_br_labels[i][0] = training_tr_labels[i][0]\n",
    "    training_br_labels[i][1] = 500 - training_tr_labels[i][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Delete overlapping data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_tl = np.delete(np.asarray(training_tl), np.where(np.asanyarray(training_tl_labels) == 250.)[0], axis = 0)\n",
    "training_tl_labels = np.delete(np.asarray(training_tl_labels), np.where(np.asanyarray(training_tl_labels) == 250.)[0], axis = 0)\n",
    "\n",
    "training_bl = np.delete(np.asarray(training_bl), 0, axis = 0)\n",
    "training_bl_labels = np.delete(np.asarray(training_bl_labels), 0, axis = 0)\n",
    "\n",
    "training_br = np.delete(np.asarray(training_br), np.where(np.asanyarray(training_br_labels) == 250.)[0], axis = 0)\n",
    "training_br_labels = np.delete(np.asarray(training_br_labels), np.where(np.asanyarray(training_br_labels) == 250.)[0], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Makesure the augmentation is done on all quadrants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{np.asarray(training_tl).shape} \\t{np.asarray(training_tr).shape} \\n{np.asarray(training_bl).shape} \\t{np.asarray(training_br).shape} \\n{counter}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "for i in range(0, len(training_tr_labels)):\n",
    "    plt.plot(training_tr_labels[i][0], training_tr_labels[i][1], 'o', c = 'r')\n",
    "for j in range (0, len(training_tl_labels)):\n",
    "    plt.plot(training_tl_labels[j][0], training_tl_labels[j][1], 's', c = 'g')\n",
    "    plt.plot(training_br_labels[j][0], training_br_labels[j][1], 'P', c = 'y')\n",
    "for k in range (0, len(training_bl_labels)):\n",
    "    plt.plot(training_bl_labels[k][0], training_bl_labels[k][1], '*', c = 'b')\n",
    "\n",
    "plt.xticks(np.arange(175, 330, 5), rotation = 'vertical')\n",
    "plt.yticks(np.arange(175, 330, 5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate, Cut, Normalize, Resample Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = np.concatenate((training_tr, training_tl, training_bl, training_br), axis = 0)\n",
    "training_labels = np.concatenate((training_tr_labels, training_tl_labels, training_bl_labels, training_br_labels), axis = 0)\n",
    "\n",
    "print(f'Shape of all training set: {training.shape} \\nShape of all training labels: {training_labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### check with the validation augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "fig, axs = plt.subplots(2, 4, sharex=True)\n",
    "\n",
    "val_c = 1 # Given validation folder has 4 data points. so use - (0, 1, 2, 3)\n",
    "\n",
    "# find out the index of the validation set in the training data\n",
    "x = []\n",
    "for i in range (0, len(training_labels)):\n",
    "    if (training_labels[i][0] == validation_aug_labels[val_c][0]) and (training_labels[i][1] == validation_aug_labels[val_c][1]):\n",
    "        x.append(i)\n",
    "\n",
    "# plot to compare the validation set with the training set\n",
    "fig.suptitle(f'EPOT Training Data Coordinates - {training_labels[x[0]]} \\nValidation Augmented Data Coordinates - {validation_aug_labels[val_c]}')\n",
    "\n",
    "axs[0,0].plot(training[x[0]][:,0], training[x[0]][:,1], label='P - 1', c = 'r')\n",
    "axs[0,1].plot(training[x[0]][:,0], training[x[0]][:,2], label='P - 2', c = 'g')\n",
    "axs[0,2].plot(training[x[0]][:,0], training[x[0]][:,3], label='P - 3', c = 'b')\n",
    "axs[0,3].plot(training[x[0]][:,0], training[x[0]][:,4], label='P - 4', c = 'y')\n",
    "\n",
    "axs[1,0].plot(validation_aug[val_c][:,0], validation_aug[val_c][:,1], label='P - 1', c = 'r')\n",
    "axs[1,1].plot(validation_aug[val_c][:,0], validation_aug[val_c][:,2], label='P - 2', c = 'g')\n",
    "axs[1,2].plot(validation_aug[val_c][:,0], validation_aug[val_c][:,3], label='P - 3', c = 'b')\n",
    "axs[1,3].plot(validation_aug[val_c][:,0], validation_aug[val_c][:,4], label='P - 4', c = 'y')\n",
    "\n",
    "# check if the data is exactly the same\n",
    "for i in range (1, 5):\n",
    "    if np.all(training[x[0]][:,i] == validation_aug[val_c][:,i], axis = 0):\n",
    "        print('Data is augmented correctly')\n",
    "\n",
    "fig.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = training[x[0]][:,1] - validation_aug[val_c][:,1]\n",
    "diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### -- Check -- for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "fig, axs = plt.subplots(2, 2, sharex=True, sharey=True)\n",
    "\n",
    "for i in range(len(training)):\n",
    "    axs[0,0].plot(training[i][:,0], training[i][:,1], label='Training P-1')\n",
    "    axs[0,1].plot(training[i][:,0], training[i][:,2], label='Training P-2')\n",
    "    axs[1,0].plot(training[i][:,0], training[i][:,3], label='Training P-3')\n",
    "    axs[1,1].plot(training[i][:,0], training[i][:,4], label='Training P-4')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sns.set(rc={'figure.figsize':(30, 30)})\n",
    "\n",
    "x = []; y = []; z = []\n",
    "\n",
    "for i in range(len(training)):\n",
    "    xi = training_labels[i][0]\n",
    "    x.append(xi)\n",
    "    yi = training_labels[i][1]\n",
    "    y.append(yi)\n",
    "    zi = pd.DataFrame(training[i][:,1]).max()[0]\n",
    "    # zi = pd.DataFrame(training[i][:,2]).max()[0]\n",
    "    # zi = pd.DataFrame(training[i][:,3]).max()[0]\n",
    "    # zi = pd.DataFrame(training[i][:,4]).max()[0]\n",
    "\n",
    "    z.append(zi)\n",
    "\n",
    "df = pd.DataFrame({'x': x, 'y': y, 'z': z})\n",
    "\n",
    "heatmap1_data = pd.pivot_table(df, values='z', index=['y'], columns='x')\n",
    "\n",
    "ax = sns.heatmap(heatmap1_data, \n",
    "                square=True, \n",
    "                annot = True, \n",
    "                annot_kws={\"fontsize\": 10}, \n",
    "                fmt='.1f', \n",
    "                linewidths=0.1, \n",
    "                linecolor='gray',\n",
    "                cbar_kws = dict(use_gridspec=False, location='right'))\n",
    "\n",
    "ax.invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimental Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "sns.set(rc={'figure.figsize':(30, 30)})\n",
    "\n",
    "x = []; y = []; z = []\n",
    "\n",
    "for i in range(len(ex_val_data)):\n",
    "    xi = ex_val_labels[i][0]\n",
    "    x.append(xi)\n",
    "    yi = ex_val_labels[i][1]\n",
    "    y.append(yi)\n",
    "    zi = pd.DataFrame(ex_val_data[i][:,1]).max()[0]\n",
    "    # zi = pd.DataFrame(training[i][:,2]).max()[0]\n",
    "    # zi = pd.DataFrame(training[i][:,3]).max()[0]\n",
    "    # zi = pd.DataFrame(training[i][:,4]).max()[0]\n",
    "\n",
    "    z.append(zi)\n",
    "\n",
    "df = pd.DataFrame({'x': x, 'y': y, 'z': z})\n",
    "\n",
    "heatmap1_data = pd.pivot_table(df, values='z', index=['y'], columns='x')\n",
    "\n",
    "ax = sns.heatmap(heatmap1_data, \n",
    "                square=True, \n",
    "                annot = True, \n",
    "                annot_kws={\"fontsize\": 10}, \n",
    "                fmt='.1f', \n",
    "                linewidths=0.1, \n",
    "                linecolor='gray',\n",
    "                cbar_kws = dict(use_gridspec=False, location='right'))\n",
    "\n",
    "ax.invert_yaxis()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cutting Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cut = []\n",
    "for i in range(len(training)):\n",
    "    \n",
    "    threshold = 0.1\n",
    "\n",
    "    x = np.where(abs(training[i][:,1])>threshold)[0][0]\n",
    "    y = np.where(abs(training[i][:,2])>threshold)[0][0]\n",
    "    z = np.where(abs(training[i][:,3])>threshold)[0][0]\n",
    "    p = np.where(abs(training[i][:,4])>threshold)[0][0]\n",
    "\n",
    "    start = min(x,y,z,p)\n",
    "\n",
    "    d = np.empty_like(training[i][start:,:])\n",
    "\n",
    "    d[:,0] = training[i][start:, 0]\n",
    "    d[:,1] = training[i][start:, 1]\n",
    "    d[:,2] = training[i][start:, 2]\n",
    "    d[:,3] = training[i][start:, 3]\n",
    "    d[:,4] = training[i][start:, 4]\n",
    "\n",
    "    train_cut.append(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalize Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maxim = []\n",
    "# minim = []\n",
    "# for i in range (len(train_cut)):\n",
    "#     for j in range (1,5):\n",
    "#         p = train_cut[i][:,j].max()\n",
    "#         q = train_cut[i][:,j].min()\n",
    "\n",
    "#         maxim.append(p)\n",
    "#         minim.append(q)\n",
    "# # print(np.asarray(maxim).max(),np.asarray(minim).min())\n",
    "\n",
    "# create variables for normalized data\n",
    "# train_norm = np.zeros_like(np.array(train_cut)) \n",
    "train_norm = []\n",
    "train_norm_labels = np.zeros_like(np.asarray(training_labels))\n",
    "\n",
    "for i in range (0, len(train_cut)):\n",
    "    \n",
    "    n = np.zeros_like(train_cut[i])\n",
    "    n[:,1] = minmax_scale(train_cut[i][:,1])\n",
    "    n[:,2] = minmax_scale(train_cut[i][:,2])\n",
    "    n[:,3] = minmax_scale(train_cut[i][:,3])\n",
    "    n[:,4] = minmax_scale(train_cut[i][:,4])\n",
    "    \n",
    "    train_norm.append(n)\n",
    "\n",
    "    \n",
    "scalar = MinMaxScaler()\n",
    "train_norm_labels = scalar.fit_transform(training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxim = []\n",
    "minim = []\n",
    "for i in range (len(train_norm)):\n",
    "    for j in range (1,5):\n",
    "        p = train_norm[i][:,j].max()\n",
    "        q = train_norm[i][:,j].min()\n",
    "\n",
    "        maxim.append(p)\n",
    "        minim.append(q)\n",
    "print(np.asarray(maxim).max(),np.asarray(minim).min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plt.plot(train_norm_labels[:,0], train_norm_labels[:,1], 'o', c = 'r', label = 'Normalized Training Data Labels')\n",
    "plt.legend(loc='lower center', bbox_to_anchor=(1, -0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Resample Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_resample = []\n",
    "\n",
    "# create a dataframe from the normalized data\n",
    "for i in range (0, len(training)):\n",
    "    train_resample.append(pd.DataFrame(train_norm[i], columns = ['time', '1', '2', '3', '4']))\n",
    "    # drop the time column\n",
    "    train_resample[i] = train_resample[i].drop(columns = ['time'])\n",
    "\n",
    "size = 100\n",
    "\n",
    "for i in range (0, len(training)):\n",
    "    train_resample[i] = resample(train_resample[i], size)\n",
    "\n",
    "np.asarray(train_resample).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "fig, axs = plt.subplots(2, 1)\n",
    "\n",
    "axs[0].plot(training[10][:,2], c = 'r', label = 'Original Training Data')\n",
    "axs[1].plot(train_resample[10][:,1], c = 'b', label = 'cut/ norm/ resampled Data')\n",
    "\n",
    "axs[0].legend(loc='lower left')\n",
    "axs[1].legend(loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare Experimental, Experimental-Validation and Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "fig, axs = plt.subplots(2, 4, sharey=True)\n",
    "\n",
    "ex_val_c = 20 # Given validation folder has 24 data points. so use - (0, 1, .... , 23)\n",
    "\n",
    "# find out the index of the validation set in the training data\n",
    "x = []\n",
    "for i in range (0, len(training_labels)):\n",
    "    if (training_labels[i][0] == ex_val_labels[ex_val_c][0]) and (training_labels[i][1] == ex_val_labels[ex_val_c][1]):\n",
    "        x.append(i)\n",
    "\n",
    "# plot to compare the validation set with the training set\n",
    "fig.suptitle(f'Training Data Coordinates - {training_labels[x[0]]} \\nExperimental Validation Data Coordinates - {ex_val_labels[ex_val_c]} - Trial [{ex_val_trails[ex_val_c]}]')\n",
    "\n",
    "axs[0,0].plot(training[x[0]][:,0], training[x[0]][:,1], label='P - 1', c = 'r')\n",
    "axs[0,1].plot(training[x[0]][:,0], training[x[0]][:,2], label='P - 2', c = 'g')\n",
    "axs[0,2].plot(training[x[0]][:,0], training[x[0]][:,3], label='P - 3', c = 'b')\n",
    "axs[0,3].plot(training[x[0]][:,0], training[x[0]][:,4], label='P - 4', c = 'y')\n",
    "\n",
    "axs[1,0].plot(ex_val_cut_data[ex_val_c][:,0], ex_val_cut_data[ex_val_c][:,1], label='P - 1', c = 'r')\n",
    "axs[1,1].plot(ex_val_cut_data[ex_val_c][:,0], ex_val_cut_data[ex_val_c][:,2], label='P - 2', c = 'g')\n",
    "axs[1,2].plot(ex_val_cut_data[ex_val_c][:,0], ex_val_cut_data[ex_val_c][:,3], label='P - 3', c = 'b')\n",
    "axs[1,3].plot(ex_val_cut_data[ex_val_c][:,0], ex_val_cut_data[ex_val_c][:,4], label='P - 4', c = 'y')\n",
    "\n",
    "# fig.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "fig, axs = plt.subplots(1, 4, sharex=True, sharey=True)\n",
    "\n",
    "for i in range(4):\n",
    "    axs[0].plot(ex_val_cut_data[i][:,0], ex_val_cut_data[i][:,1], c = 'r', label = 'Exp Val Data - P-1')\n",
    "    axs[1].plot(ex_val_cut_data[i][:,0], ex_val_cut_data[i][:,2], c = 'g', label = 'Exp Val Data - P-2')\n",
    "    axs[2].plot(ex_val_cut_data[i][:,0], ex_val_cut_data[i][:,3], c = 'b', label = 'Exp Val Data - P-3')\n",
    "    axs[3].plot(ex_val_cut_data[i][:,0], ex_val_cut_data[i][:,4], c = 'y', label = 'Exp Val Data - P-4')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export data to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('training_data.pickle', 'wb') as f:\n",
    "#     pickle.dump(training, f)\n",
    "\n",
    "# with open('train_resample.pickle', 'wb') as f:\n",
    "#     pickle.dump(train_resample, f)\n",
    "# with open('train_norm_labels.pickle', 'wb') as f:\n",
    "#     pickle.dump(train_norm_labels, f)\n",
    "\n",
    "# with open('training_labels.pickle', 'wb') as f:\n",
    "#     pickle.dump(training_labels, f)\n",
    "\n",
    "# with open('exp_validation_data.pickle', 'wb') as f:\n",
    "#     pickle.dump(ex_val_data, f)\n",
    "# with open('exp_validation_labels.pickle', 'wb') as f:\n",
    "#     pickle.dump(ex_val_labels, f)\n",
    "# with open('exp_validation_trails.pickle', 'wb') as f:\n",
    "#     pickle.dump(ex_val_trails, f)\n",
    "\n",
    "\n",
    "# with open('exp_val_resample.pickle', 'wb') as f:\n",
    "#     pickle.dump(ex_val_resample, f)\n",
    "# with open('exp_val_norm_labels.pickle', 'wb') as f:\n",
    "#     pickle.dump(ex_val_norm_labels, f)\n",
    "\n",
    "# with open('ex_resample.pickle', 'wb') as f:\n",
    "#     pickle.dump(ex_resample, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AI Model Tuning and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the data from the pickle files\n",
    "'''\n",
    "with open('train_resample.pickle', 'rb') as f:\n",
    "    train_resample = pickle.load(f)\n",
    "with open('train_norm_labels.pickle', 'rb') as f:\n",
    "    train_norm_labels = pickle.load(f)\n",
    "'''\n",
    "\n",
    "X = np.asarray(train_resample)\n",
    "y = np.asarray(train_norm_labels)\n",
    "\n",
    "# create split data from the normalized data\n",
    "size = 0.2\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, shuffle=True, test_size=size)\n",
    "print(f'Length of training data - {len(x_train)} length of labels - {len(y_train)} \\nLength of test data - {len(x_test)} length of labels - {len(y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorboard --logdir=logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Training and Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DNN Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "log_files = f'DNN_log.{int(time.time())}'\n",
    "tuner_logs= f'tunelog/DNN_tuner_log.{int(time.time())}'\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=f'logs/{log_files}', \n",
    "                          histogram_freq=1, \n",
    "                          write_graph=True,\n",
    "                          write_grads=True)\n",
    "\n",
    "\n",
    "def dnnModel(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(100,4)))\n",
    "    model.add(Dense(units=hp.Int('layer_1_nodes', \n",
    "                    min_value=32, max_value=512, step=32), \n",
    "                    activation=hp.Choice(\"activation_1\", [\"relu\", \"sigmoid\", \"tanh\"])))\n",
    "    \n",
    "    for i in range(hp.Int('n_layers', min_value=0, max_value=4, step=1)):\n",
    "        model.add(Dense(units=hp.Int(f'layer_{i+1}_nodes', min_value=32, max_value=512, step=32), activation=hp.Choice(f\"activation_{i+1}\", [\"relu\", \"sigmoid\", \"tanh\"])))\n",
    "    \n",
    "    model.add(Dense(units=2, activation=hp.Choice(\"activation_out\", ['sigmoid', 'linear']))) # output layer\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    # Compile model\n",
    "    # lr = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "    sgd = tf.keras.optimizers.SGD(learning_rate=0.0001)\n",
    "\n",
    "    model.compile(loss = hp.Choice('loss', ['mae']),\n",
    "                optimizer = hp.Choice('optimizer', ['Adam', 'RMSprop']), \n",
    "                metrics=['Accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Hyperparameter tuning\n",
    "tuner = RandomSearch(dnnModel,\n",
    "                    objective='val_Accuracy',\n",
    "                    max_trials=50,\n",
    "                    executions_per_trial=2,\n",
    "                    directory=tuner_logs,\n",
    "                    project_name='DNN_tuning')\n",
    "\n",
    "tuner.search(x=x_train,\n",
    "            y=y_train,\n",
    "            epochs=60,\n",
    "            batch_size=32,\n",
    "            validation_data=(x_test, y_test),\n",
    "            callbacks=[tensorboard])\n",
    "            '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bestModels = tuner.get_best_models(num_models=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the keras model\n",
    "# model.save(f'model/complete_tunedModel_97perAcc.{int(time.time())}.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "log_files = f'CNN_log.{int(time.time())}'\n",
    "tuner_logs= f'tunelog/CNN_tuner_log.{int(time.time())}'\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=f'logs/{log_files}', \n",
    "                          histogram_freq=1, \n",
    "                          write_graph=True,\n",
    "                          write_grads=True)\n",
    "\n",
    "def cnnModel(hp):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv1D(filters=hp.Int('conv_1_filter', min_value=32, max_value=512, step=32), \n",
    "                     kernel_size=hp.Int('Kernal_1', min_value=2, max_value=5, step=1), \n",
    "                     strides=hp.Int('stride_1', min_value=1, max_value=5, step=1),\n",
    "                     activation=hp.Choice(\"activation_1\", [\"relu\", \"sigmoid\"]), \n",
    "                     input_shape=(100,4)))\n",
    "    \n",
    "    model.add(MaxPooling1D(pool_size=hp.Int('pool_1', min_value=2, max_value=5, step=1))),\n",
    "\n",
    "    for i in range(hp.Int('n_layers', min_value=0, max_value=4, step=1)):\n",
    "        model.add(Conv1D(filters=hp.Int(f'conv_{i+1}_filter', min_value=32, max_value=512, step=32), \n",
    "                         kernel_size=hp.Int(f'Kernal_{i+1}', min_value=2, max_value=5, step=1), \n",
    "                         strides=hp.Int(f'stride_{i+1}', min_value=1, max_value=5, step=1),\n",
    "                         activation=hp.Choice(f\"activation_{i+1}\", [\"relu\", \"sigmoid\"])))\n",
    "        model.add(MaxPooling1D(pool_size=hp.Int(f'pool_{i+1}', min_value=2, max_value=5, step=1)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "\n",
    "    model.add(Dense(units=hp.Int('FC_layer_1_nodes',\n",
    "                    min_value=32, max_value=512, step=32),\n",
    "                    activation=hp.Choice(\"FC_activation_1\", [\"relu\", \"sigmoid\"])))\n",
    "    \n",
    "    model.add(Dense(units=hp.Int('FC_layer_2_nodes',\n",
    "                    min_value=32, max_value=512, step=32),\n",
    "                    activation=hp.Choice(\"FC_activation_2\", [\"relu\", \"sigmoid\"])))\n",
    "\n",
    "    model.add(Dense(units=2, activation=hp.Choice(\"activation_out\", ['sigmoid', 'linear']))) # output layer\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    # Compile model\n",
    "    # lr = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "    sgd = tf.keras.optimizers.SGD(learning_rate=0.0001)\n",
    "\n",
    "    model.compile(loss = hp.Choice('loss', ['mse', 'mae']),\n",
    "                optimizer = hp.Choice('optimizer', ['Adam', 'RMSprop']), \n",
    "                metrics=['Accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Hyperparameter tuning\n",
    "tuner = RandomSearch(cnnModel,\n",
    "                    objective='val_Accuracy',\n",
    "                    max_trials=560,\n",
    "                    executions_per_trial=3,\n",
    "                    directory=tuner_logs,\n",
    "                    project_name='CNN_tuning')\n",
    "\n",
    "tuner.search(x=x_train,\n",
    "            y=y_train,\n",
    "            epochs=60,\n",
    "            batch_size=32,\n",
    "            validation_data=(x_test, y_test),\n",
    "            callbacks=[tensorboard])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bestModels = tuner.get_best_models(num_models=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FFNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(100,4)))\n",
    "\n",
    "model.add(Dense(units=512, activation='relu'))\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dense(units=96, activation='relu'))\n",
    "model.add(Dense(units=12, activation='relu'))\n",
    "\n",
    "model.add(Dense(units=2, activation='linear'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Compile model\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "model.compile(loss = 'mse', optimizer = 'Adam', metrics=['Accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(x_train, y_train, epochs=50, verbose=1, batch_size=32, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(f'model/DNN_val_acc_97perAcc.{int(time.time())}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(scalar.inverse_transform(y_test), scalar.inverse_transform(model.predict(x_test)), squared=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_squared_error((ex_val_labels), scalar.inverse_transform(model.predict(ex_val_resample)), squared=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.plot(history.history['Accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_Accuracy'], label='Validation Accuracy')\n",
    "\n",
    "plt.yticks(np.arange(0, 1, 0.05))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mAlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Alex4=Sequential()\n",
    "\n",
    "Alex4.add(Conv1D(filters=96, kernel_size=5, strides=4, activation='relu', input_shape=(100,4), padding='same'))\n",
    "Alex4.add(MaxPooling1D(pool_size=3, strides= 2, padding='valid'))\n",
    "Alex4.add(Dropout(0.3))\n",
    "\n",
    "Alex4.add(Conv1D(filters=256, strides=1, kernel_size=5, activation='relu', padding='same'))\n",
    "Alex4.add(MaxPooling1D(pool_size=3, strides=2, padding='valid'))\n",
    "\n",
    "Alex4.add(Conv1D(filters=384, strides=1, kernel_size=3, activation='relu', padding='same'))\n",
    "Alex4.add(Dropout(0.4))\n",
    "\n",
    "Alex4.add(Conv1D(filters=256, strides=1, kernel_size=3, activation='relu', padding='same'))\n",
    "\n",
    "Alex4.add(Conv1D(filters=256, strides=1, kernel_size=3, activation='relu', padding='same'))\n",
    "Alex4.add(MaxPooling1D(pool_size=3, strides=2, padding='valid'))\n",
    "\n",
    "# Fully Connected Layers\n",
    "Alex4.add(Flatten())\n",
    "Alex4.add(Dense(units=128, activation='relu',use_bias='False'))\n",
    "Alex4.add(Dense(units=64, activation='relu',use_bias='False'))\n",
    "Alex4.add(Dense(units=2, activation='linear',use_bias='False'))\n",
    "Alex4.summary()\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "Alex4.compile(loss = 'mse', optimizer = 'Adam', metrics=['Accuracy'])\n",
    "\n",
    "# Fit the cnn_model\n",
    "Alex_history = Alex4.fit(x_train, y_train, epochs=90, verbose=1, batch_size=32, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(scalar.inverse_transform(y_test), scalar.inverse_transform(Alex4.predict(x_test)), squared=True)\n",
    "# mean_absolute_error(scalar.inverse_transform(y_test), scalar.inverse_transform(Alex4.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alex4.save(f'model/FINAL_CNN_val_acc_97_16_MSE.{int(time.time())}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plt.plot(Alex_history.history['loss'], label='Training Loss')\n",
    "plt.plot(Alex_history.history['val_loss'], label='Validation Loss')\n",
    "plt.plot(Alex_history.history['Accuracy'], label='Training Accuracy')\n",
    "plt.plot(Alex_history.history['val_Accuracy'], label='Validation Accuracy')\n",
    "\n",
    "plt.yticks(np.arange(0, 1, 0.05))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extension Other Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_bn(inputs: Tensor) -> Tensor:\n",
    "    bn = BatchNormalization()(inputs)\n",
    "    relu = ReLU()(bn)\n",
    "    return relu\n",
    "\n",
    "def CNN_block(x: Tensor, filters: int, kernel_size: int = 3) -> Tensor:\n",
    "    # i = BatchNormalization()(x)\n",
    "    j = Conv1D(kernel_size=3,\n",
    "            strides=1,\n",
    "            filters=filters,\n",
    "            padding=\"same\")(x)\n",
    "    return j\n",
    "\n",
    "def residual_block(x: Tensor, filters: int, kernel_size: int = 3) -> Tensor:\n",
    "    y = Conv1D(kernel_size=kernel_size,\n",
    "               strides= 1,\n",
    "               filters=filters,\n",
    "               padding=\"same\")(x)\n",
    "    y = relu_bn(y)\n",
    "    y = Conv1D(kernel_size=kernel_size,\n",
    "               strides=1,\n",
    "               filters=filters,\n",
    "               padding=\"same\")(y)\n",
    "    y = BatchNormalization()(y)\n",
    "\n",
    "    out = Add()([x, y])\n",
    "    out = relu_bn(out)\n",
    "    return out\n",
    "\n",
    "def create_res_net():\n",
    "    \n",
    "    inputs = Input(shape=(100,4))\n",
    "    num_filters = 64\n",
    "    \n",
    "    t = BatchNormalization()(inputs)\n",
    "    t = Conv1D(kernel_size=3,\n",
    "               strides=1,\n",
    "               filters=num_filters,\n",
    "               padding=\"same\")(t)\n",
    "    t = relu_bn(t)\n",
    "        \n",
    "    num_blocks_list = [2, 1, 2]\n",
    "    t = CNN_block(t, filters = 128)\n",
    "    for j in range(num_blocks_list[0]):\n",
    "        t = residual_block(t, filters=128)\n",
    "\n",
    "    t = Dropout(0.3)(t)\n",
    "\n",
    "    t = CNN_block(t, filters = 64)\n",
    "    for j in range(num_blocks_list[1]):\n",
    "        t = residual_block(t, filters=64)\n",
    "    \n",
    "    t = Dropout(0.3)(t)\n",
    "\n",
    "    t = CNN_block(t, filters = 64)\n",
    "    for j in range(num_blocks_list[2]):\n",
    "        t = residual_block(t, filters=64)\n",
    "    \n",
    "    t = AveragePooling1D(pool_size = 3)(t)\n",
    "    t = Flatten()(t)\n",
    "    # t = Dense(units=128, activation='relu')(t)\n",
    "    t = Dense(units=32, activation=\"relu\")(t)\n",
    "    outputs = Dense(2, activation='linear')(t)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='Adam',\n",
    "        loss='mse',\n",
    "        metrics=['Accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "rnet1 = create_res_net() # or create_plain_net()\n",
    "rnet1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestr = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# name = 'cifar-10_res_net_30-'+timestr # or 'cifar-10_plain_net_30-'+timestr\n",
    "\n",
    "# checkpoint_path = \"checkpoints/\"+name+\"/cp-{epoch:04d}.ckpt\"\n",
    "# checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "# os.system('mkdir {}'.format(checkpoint_dir))\n",
    "\n",
    "# # save model after each epoch\n",
    "# cp_callback = ModelCheckpoint(\n",
    "#     filepath=checkpoint_path,\n",
    "#     verbose=1\n",
    "# )\n",
    "# tensorboard_callback = TensorBoard(\n",
    "#     log_dir='tensorboard_logs/'+name,\n",
    "#     histogram_freq=1\n",
    "# )\n",
    "\n",
    "rNet1_history = rnet1.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    epochs=90,\n",
    "    verbose=1,\n",
    "    validation_data=(x_test, y_test),\n",
    "    batch_size=32,\n",
    "    # callbacks=[cp_callback, tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(scalar.inverse_transform(y_test), scalar.inverse_transform(rnet1.predict(x_test)), squared=True)\n",
    "# mean_absolute_error(scalar.inverse_transform(y_test), scalar.inverse_transform(rnet.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plt.plot(rNet1_history.history['loss'], label='Training Loss')\n",
    "plt.plot(rNet1_history.history['val_loss'], label='Validation Loss')\n",
    "plt.plot(rNet1_history.history['Accuracy'], label='Training Accuracy')\n",
    "plt.plot(rNet1_history.history['val_Accuracy'], label='Validation Accuracy')\n",
    "\n",
    "plt.yticks(np.arange(0, 1, 0.05))\n",
    "plt.ylim(bottom=0, top=1)\n",
    "plt.tight_layout()\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnet.save('ResNet-60MSE.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG2 = Sequential()\n",
    "\n",
    "VGG2.add(Conv1D(filters=64, kernel_size=3, strides=2,activation='relu', input_shape=(100,4), padding='same'))\n",
    "VGG2.add(Conv1D(filters=64, kernel_size=3, strides=1,activation='relu',padding='valid'))\n",
    "VGG2.add(Conv1D(filters=64, kernel_size=1, strides=1,activation='relu' ))\n",
    "\n",
    "VGG2.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "\n",
    "VGG2.add(Conv1D(filters=128, kernel_size=3, strides=1,activation='relu',padding='valid'))\n",
    "VGG2.add(Conv1D(filters=128, kernel_size=1, strides=1,activation='relu' ))\n",
    "\n",
    "VGG2.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "\n",
    "VGG2.add(Conv1D(filters=256, kernel_size=3, strides=1,activation='relu',padding='valid'))\n",
    "VGG2.add(Conv1D(filters=256, kernel_size=1, strides=1,activation='relu' ))\n",
    "\n",
    "VGG2.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "\n",
    "VGG2.add(Conv1D(filters=256, kernel_size=3, strides=1,activation='relu',padding='valid'))\n",
    "VGG2.add(Conv1D(filters=384, kernel_size=1, strides=1,activation='relu'))\n",
    "VGG2.add(Conv1D(filters=100, kernel_size=1, strides=1,activation='relu'))\n",
    "VGG2.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "\n",
    "VGG2.add(Flatten())\n",
    "\n",
    "VGG2.add(Dense(units=2,activation='linear'))\n",
    "\n",
    "VGG2.summary()\n",
    "\n",
    "VGG2.compile(loss = 'mse', optimizer = 'Adam', metrics=['Accuracy'])\n",
    "VGG2_act=VGG2.fit(x_train, y_train, epochs=40, verbose=1, batch_size=32, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(scalar.inverse_transform(y_test), scalar.inverse_transform(VGG2.predict(x_test)), squared=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plt.plot(VGG2_act.history['loss'], label='Training Loss')\n",
    "plt.plot(VGG2_act.history['val_loss'], label='Validation Loss')\n",
    "plt.plot(VGG2_act.history['Accuracy'], label='Training Accuracy')\n",
    "plt.plot(VGG2_act.history['val_Accuracy'], label='Validation Accuracy')\n",
    "\n",
    "plt.yticks(np.arange(0, 1, 0.05))\n",
    "plt.ylim(0, 1)\n",
    "plt.tight_layout()\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict experimental validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model('model/tunedModel_98perAcc.1640573960.h5')\n",
    "# model = tf.keras.models.load_model('Alex3.h5')\n",
    "# model = tf.keras.models.load_model('model/CNN_val_acc_96_48_MSEperAcc.1642513870.h5')\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = Alex4.predict(np.asarray(ex_val_resample))\n",
    "y_abs = ex_val_labels\n",
    "\n",
    "y_pred = scalar.inverse_transform(np.asarray(y_pred))\n",
    "diff = y_abs-y_pred\n",
    "for i in range(len(y_pred)):\n",
    "    print(f'Absolute Trial {ex_val_trails[i]}- {y_abs[i]} Predicted - {y_pred[i]} \\tDifference - {y_abs[i] - y_pred[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_abs, y_pred, squared=True)\n",
    "mean_absolute_error(y_abs, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experimental Group - 7 Data (and post-processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_g7 = Alex4.predict(np.asarray(ex_resample))\n",
    "y_pred_g7 = scalar.inverse_transform(y_pred_g7)\n",
    "y_pred_g7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "fig, axs = plt.subplots(2, 4, sharey=True)\n",
    "\n",
    "ex_c = 1 # Given validation folder has 18 data points. so use - (0, 1, .... , 17)\n",
    "\n",
    "# find out the index of the validation set in the training data\n",
    "p = []\n",
    "\n",
    "for i in range (len(y_pred_g7)):\n",
    "    xi = np.where(training_labels[:,0] == min(training_labels[:,0], key=lambda x:abs(x-y_pred_g7[i][0])))[0]\n",
    "    yi = np.where(training_labels[:,1] == min(training_labels[:,1], key=lambda x:abs(x-y_pred_g7[i][1])))[0]\n",
    "    pi = np.intersect1d(xi, yi)[0]\n",
    "    \n",
    "    p.append(pi)\n",
    "\n",
    "# plot to compare the validation set with the training set\n",
    "fig.suptitle(f'Closest Training Data Coordinates - {training_labels[p[ex_c]]} \\nExperimental Predicted Coordinates - {y_pred_g7[ex_c]}')\n",
    "\n",
    "axs[0,0].plot(training[p[ex_c]][:,1], label='P - 1', c = 'r')\n",
    "axs[0,1].plot(training[p[ex_c]][:,2], label='P - 2', c = 'g')\n",
    "axs[0,2].plot(training[p[ex_c]][:,3], label='P - 3', c = 'b')\n",
    "axs[0,3].plot(training[p[ex_c]][:,4], label='P - 4', c = 'y')\n",
    "\n",
    "axs[1,0].plot(ex_cut_data[ex_c][:,1], label='P - 1', c = 'r')\n",
    "axs[1,1].plot(ex_cut_data[ex_c][:,2], label='P - 2', c = 'g')\n",
    "axs[1,2].plot(ex_cut_data[ex_c][:,3], label='P - 3', c = 'b')\n",
    "axs[1,3].plot(ex_cut_data[ex_c][:,4], label='P - 4', c = 'y')\n",
    "\n",
    "# fig.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Post processing of mAlexNet model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sorting the exact experimental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Group_7\tAA\t250\t265\n",
    "Group_7\tAA\t245\t255\n",
    "Group_7\tAA\t235\t235\n",
    "Group_7\tAA\t265\t235\n",
    "Group_7\tAA\t250\t250\n",
    "Group_7\tAA\t255\t265\n",
    "Group_7\tB\t225\t200\n",
    "Group_7\tB\t270\t300\n",
    "Group_7\tB\t200\t225\n",
    "Group_7\tB\t235\t300\n",
    "Group_7\tB\t260\t320\n",
    "Group_7\tB\t300\t285\n",
    "Group_7\tA\t250\t265\n",
    "Group_7\tA\t245\t255\n",
    "Group_7\tA\t235\t235\n",
    "Group_7\tA\t265\t235\n",
    "Group_7\tA\t250\t250\n",
    "Group_7\tA\t265\t255\n",
    "'''\n",
    "\n",
    "exact_ex_labels = np.array(\n",
    "[[250,\t265], \n",
    "[245,\t255],\n",
    "[235,\t235],\n",
    "[265,\t235],\n",
    "[250,\t250],\n",
    "[255,\t265],\n",
    "[225,\t200],\n",
    "[270,\t300],\n",
    "[200,\t225],\n",
    "[235,\t300],\n",
    "[260,\t320],\n",
    "[300,\t285],\n",
    "[250,\t265],\n",
    "[245,\t255],\n",
    "[235,\t235],\n",
    "[265,\t235],\n",
    "[250,\t250],\n",
    "[265,\t255]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions made from AlexNet model\n",
    "pred_ex_labels = np.array(\n",
    "[[253.32326, 244.85556],\n",
    "[234.51955, 233.11015],\n",
    "[243.45721, 259.58542],\n",
    "[260.85577, 225.5717 ],\n",
    "[241.64229, 252.67258],\n",
    "[262.7103 , 247.9715 ],\n",
    "[236.75409, 299.41733],\n",
    "[230.32304, 228.36177],\n",
    "[264.8639 , 298.7226 ],\n",
    "[252.88496, 258.21362],\n",
    "[260.63187, 232.50989],\n",
    "[252.09583, 252.05911],\n",
    "[201.56601, 229.92183],\n",
    "[256.91928, 257.9066 ],\n",
    "[245.16226, 252.61618],\n",
    "[224.14635, 201.8915 ],\n",
    "[269.60422, 310.06744],\n",
    "[298.5857 , 281.49817]])\n",
    "\n",
    "# pred_ex_labels = scalar.inverse_transform(rnet1.predict(np.asarray(ex_resample)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(exact_ex_labels.shape, pred_ex_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plt.plot(training_labels[:,0], training_labels[:,1], '.', color = 'g', label='Training Data', alpha = 0.3)\n",
    "plt.plot(pred_ex_labels[:,0], pred_ex_labels[:,1], 'o', color = 'b', label='Predicted')\n",
    "plt.plot(exact_ex_labels[:,0], exact_ex_labels[:,1], 'o', color = 'r', label='Exact')\n",
    "plt.scatter(exact_ex_labels[:,0], exact_ex_labels[:,1], s=750, facecolors='none', edgecolors='k')\n",
    "\n",
    "plt.xticks(np.arange(175, 330, 5), rotation = 'vertical')\n",
    "plt.yticks(np.arange(175, 330, 5))\n",
    "\n",
    "legend_x = 0.5\n",
    "legend_y = -0.27\n",
    "plt.legend(bbox_to_anchor=(legend_x, legend_y), loc = 'lower center', ncol = 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "p_loc=[]\n",
    "for i in range(len(exact_ex_labels)):\n",
    "    t = []\n",
    "    for j in range(len(pred_ex_labels)):\n",
    "        xi = (np.asarray(np.abs(exact_ex_labels[i]-pred_ex_labels[j])).sum())\n",
    "        t.append(xi)\n",
    "    p_loc.append(np.argmin(t))\n",
    "    x.append(np.min(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorganising the predicted labels\n",
    "pred_ex_labels_org = np.empty_like(pred_ex_labels)\n",
    "for i in range (len(p_loc)):\n",
    "    pred_ex_labels_org[i] = pred_ex_labels[p_loc[i]]\n",
    "\n",
    "print('Exact Coordinates \\tPredicted Coordinates \\t     Difference')\n",
    "for i in range(len(p_loc)):\n",
    "    print(f'{exact_ex_labels[i]}---------------{pred_ex_labels[p_loc[i]]}--------{exact_ex_labels[i] - pred_ex_labels[p_loc[i]]}')\n",
    "\n",
    "print(f'MSE of the Group-7 data - {mean_squared_error(exact_ex_labels, pred_ex_labels_org)}')\n",
    "print(f'MAE of the Group-7 data - {mean_absolute_error(exact_ex_labels, pred_ex_labels_org)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reinforce prediction with post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = 1\n",
    "\n",
    "def find_leastmse_train(temp):\n",
    "    # find out the index of the validation set in the training data\n",
    "    p = []\n",
    "\n",
    "    for i in range (len(pred_ex_labels)):\n",
    "        xi = np.where(training_labels[:,0] == min(training_labels[:,0], key=lambda x:abs(x-pred_ex_labels[i][0])))[0]\n",
    "        yi = np.where(training_labels[:,1] == min(training_labels[:,1], key=lambda x:abs(x-pred_ex_labels[i][1])))[0]\n",
    "        pi = np.intersect1d(xi, yi)[0]\n",
    "        \n",
    "        p.append(pi)\n",
    "\n",
    "    # for i in range(len(p)):\n",
    "    #     print(f'{training_labels[p][i]} \\t {pred_ex_labels[i]}')\n",
    "\n",
    "    x_offset = [-5, 0, 5]\n",
    "    y_offset = [-5, 0, 5]\n",
    "    loc=[]; x=[]; y=[]\n",
    "\n",
    "    for k in (x_offset):\n",
    "        for l in (y_offset):\n",
    "            xi = np.where(training_labels[:,0][p][temp] + k == training_labels[:,0])\n",
    "            yi = np.where(training_labels[:,1][p][temp] + l == training_labels[:,1])\n",
    "            x.append(xi)\n",
    "            y.append(yi)\n",
    "        \n",
    "        for m in range(len(x)):\n",
    "            for n in range(len(y)):\n",
    "                loc.append(np.intersect1d(x[m], y[n])[0])\n",
    "    locs = np.unique(loc)\n",
    "\n",
    "    mse = []\n",
    "    for i in range(len(locs)):\n",
    "        err = mean_squared_error(train_resample[locs[i]], ex_resample[temp])\n",
    "        mse.append(err)\n",
    "    min_loc = locs[np.argmin(mse)]\n",
    "\n",
    "    return locs, min_loc\n",
    "\n",
    "\n",
    "\n",
    "leastmse_pred = []; leastmse_label = []\n",
    "l = []; locs = []\n",
    "\n",
    "for temp in range(len(pred_ex_labels)):\n",
    "    try:    \n",
    "        l, x = find_leastmse_train(temp)\n",
    "        locs.append(l)\n",
    "        leastmse_label.append(x)\n",
    "        leastmse_pred.append(training_labels[x])\n",
    "    except:\n",
    "        print(f'{temp} - {pred_ex_labels[temp]} surrounding points are not in the training data')\n",
    "        pass\n",
    "    \n",
    "    # print(f'loop - {temp}')\n",
    "\n",
    "leastmse_pred = np.asarray(leastmse_pred)\n",
    "leastmse_label = np.asarray(leastmse_label)\n",
    "locs = np.asarray(locs)\n",
    "\n",
    "leastmse_pred = np.insert(leastmse_pred, 3, values=[260, 225], axis=0)\n",
    "leastmse_label = np.insert(leastmse_label, 3, values=722)\n",
    "locs = np.insert(locs, 3, values=722, axis = 0)\n",
    "print(np.asarray(leastmse_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "fig, axs = plt.subplots(2, 4)\n",
    "#      |\n",
    "ex_c = 4 # <----- give the group-7 experimental label\n",
    "tr_loc = leastmse_label[ex_c] # Given validation folder has 18 data points. so use - (0, 1, .... , 17)\n",
    "\n",
    "# plot to compare the validation set with the training set\n",
    "fig.suptitle(f'Least MSE Training Data Coordinates - {training_labels[tr_loc]}mm \\nExp G7 Predicted Coordinates - {pred_ex_labels[ex_c]}mm')\n",
    "\n",
    "axs[0,0].plot(train_resample[tr_loc][:,0], label='P - 1', c = 'r')\n",
    "axs[0,1].plot(train_resample[tr_loc][:,1], label='P - 2', c = 'g')\n",
    "axs[0,2].plot(train_resample[tr_loc][:,2], label='P - 3', c = 'b')\n",
    "axs[0,3].plot(train_resample[tr_loc][:,3], label='P - 4', c = 'y')\n",
    "\n",
    "axs[1,0].plot(ex_resample[ex_c][:,0], label='P - 1', c = 'r')\n",
    "axs[1,1].plot(ex_resample[ex_c][:,1], label='P - 2', c = 'g')\n",
    "axs[1,2].plot(ex_resample[ex_c][:,2], label='P - 3', c = 'b')\n",
    "axs[1,3].plot(ex_resample[ex_c][:,3], label='P - 4', c = 'y')\n",
    "\n",
    "# fig.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point = 4\n",
    "\n",
    "plt.close()\n",
    "plt.title('Find the least MSE Training Data Coordinate')\n",
    "\n",
    "plt.plot(training_labels[:,0], training_labels[:,1], '.', color = 'g', label='Training Data', alpha = 0.3)\n",
    "plt.plot(pred_ex_labels[:,0][point], pred_ex_labels[:,1][point], 's', color = 'k', label=f'Predicted Point {np.around(pred_ex_labels[point], decimals=1)}')\n",
    "\n",
    "plt.scatter(training_labels[:,0][locs[point]], training_labels[:,1][locs[point]], c='b', alpha = 0.5, label = 'Buffer Set')\n",
    "plt.scatter(training_labels[:,0][leastmse_label[point]], training_labels[:,1][leastmse_label[point]], c = 'r', label = f'Least MSE Point {training_labels[leastmse_label[point]]}')\n",
    "\n",
    "plt.xticks(np.arange(175, 330, 5), rotation = 'vertical')\n",
    "plt.yticks(np.arange(175, 330, 5))\n",
    "\n",
    "plt.legend(bbox_to_anchor=(0.5, 0), loc = 'lower center', ncol = 2)\n",
    "plt.xlabel('X (mm)')\n",
    "plt.ylabel('Y (mm)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_resample\n",
    "y = training_labels\n",
    "\n",
    "# create split data from the normalized data\n",
    "size = 0.2\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, shuffle=True, test_size=size)\n",
    "print(f'Length of training data - {len(x_train)} length of labels - {len(y_train)} \\nLength of test data - {len(x_test)} and length of labels - {len(y_test)}')\n",
    "\n",
    "x_train_flat = []\n",
    "for i in range(len(x_train)):    \n",
    "    x_dummy = np.asarray(x_train[i]).flatten()\n",
    "    x_train_flat.append(x_dummy)\n",
    "    \n",
    "x_train_flat = np.asarray(x_train_flat)\n",
    "\n",
    "x_test_flat = []\n",
    "for i in range(len(x_test)):    \n",
    "    x_dummy = np.asarray(x_test[i]).flatten()\n",
    "    x_test_flat.append(x_dummy)\n",
    "    \n",
    "x_test_flat = np.asarray(x_test_flat)\n",
    "\n",
    "print(np.asarray(x_train_flat).shape, np.asarray(y_train).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_multirf = MultiOutputRegressor(svm.SVR(kernel='rbf', C=1e5, gamma=0.03, epsilon=0.2, tol=1e-6))\n",
    "regr_multirf.fit(x_train_flat, y_train)\n",
    "\n",
    "y_pred = regr_multirf.predict(x_test_flat)\n",
    "y_test-y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test, y_pred, squared=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_exp = regr_multirf.predict(exp_val_X_flat)\n",
    "\n",
    "mean_squared_error(exp_val_y,y_pred_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_X_flat = []\n",
    "for i in range(len(ex_resample)):\n",
    "    x_dummy = np.asarray(ex_resample[i]).flatten()\n",
    "    ex_X_flat.append(x_dummy)\n",
    "\n",
    "ex_X_flat = np.asarray(ex_X_flat)\n",
    "ex_X_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_g7_knn = regr_multirf.predict(ex_X_flat)\n",
    "y_pred_g7_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_resample\n",
    "y = training_labels\n",
    "\n",
    "exp_val_X = ex_val_resample\n",
    "exp_val_y = ex_val_labels\n",
    "\n",
    "print(np.asarray(X).shape, np.asarray(y).shape)\n",
    "\n",
    "# create split data from the normalized data\n",
    "size = 0.1\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, shuffle=True, test_size=size)\n",
    "print(f'Length of training data - {np.asarray(x_train).shape} length of labels - {np.asarray(y_train).shape} \\nLength of test data - {np.asarray(x_test).shape} and length of labels - {np.asarray(y_test).shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_flat = []\n",
    "for i in range(len(x_train)):    \n",
    "    x_dummy = np.asarray(x_train[i]).flatten()\n",
    "    x_train_flat.append(x_dummy)\n",
    "    \n",
    "x_train_flat = np.asarray(x_train_flat)\n",
    "\n",
    "x_test_flat = []\n",
    "for i in range(len(x_test)):    \n",
    "    x_dummy = np.asarray(x_test[i]).flatten()\n",
    "    x_test_flat.append(x_dummy)\n",
    "    \n",
    "x_test_flat = np.asarray(x_test_flat)\n",
    "\n",
    "exp_val_X_flat = []\n",
    "for i in range(len(exp_val_X)):\n",
    "    x_dummy = np.asarray(exp_val_X[i]).flatten()\n",
    "    exp_val_X_flat.append(x_dummy)\n",
    "\n",
    "exp_val_X_flat = np.asarray(exp_val_X_flat)\n",
    "\n",
    "print(np.asarray(x_train_flat).shape, np.asarray(y_train).shape)\n",
    "print(x_test_flat.shape, y_test.shape)\n",
    "print(exp_val_X_flat.shape, exp_val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors=5, weights='distance')\n",
    "knn.fit(x_train_flat, y_train)\n",
    "y_pred = knn.predict(x_test_flat)\n",
    "y_test-y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_exp = knn.predict(exp_val_X_flat)\n",
    "\n",
    "mean_squared_error(exp_val_y,y_pred_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_X_flat = []\n",
    "for i in range(len(ex_resample)):\n",
    "    x_dummy = np.asarray(ex_resample[i]).flatten()\n",
    "    ex_X_flat.append(x_dummy)\n",
    "\n",
    "ex_X_flat = np.asarray(ex_X_flat)\n",
    "ex_X_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_g7_knn = knn.predict(ex_X_flat)\n",
    "y_pred_g7_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots for report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('_____/rNet1_history.pickle', 'rb') as f:\n",
    "    rNet1_history = pickle.load(f)\n",
    "with open('_____/wrNet_history.pickle', 'rb') as f:\n",
    "    wrNet_history = pickle.load(f)\n",
    "with open('_____/vgg_history.pickle', 'rb') as f:\n",
    "    vgg_history = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (11, 7)\n",
    "plt.close()\n",
    "\n",
    "fig, ax  = plt.subplots(2, 2, sharey=True)\n",
    "\n",
    "ax[0, 0].plot(history.history['Accuracy'], label = 'Training Accuracy')\n",
    "ax[0, 0].plot(history.history['val_Accuracy'], label = 'Validation Accuracy')\n",
    "ax[0, 0].plot(history.history['loss'], label = 'Loss')\n",
    "ax[0, 0].plot(history.history['val_loss'], label = 'Validation Loss')\n",
    "ax[0,0].set_title('FFNN Model')\n",
    "# ax[0, 0].set_xlabel('Epochs')\n",
    "ax[0, 0].set_ylabel('Accuracy/ Loss')\n",
    "\n",
    "ax[0, 1].plot(Alex_history.history['Accuracy'])\n",
    "ax[0, 1].plot(Alex_history.history['val_Accuracy'])\n",
    "ax[0, 1].plot(Alex_history.history['loss'])\n",
    "ax[0, 1].plot(Alex_history.history['val_loss'])\n",
    "ax[0, 1].set_title('mAlexNet Model')\n",
    "# ax[0, 1].set_xlabel('Epochs')\n",
    "ax[0, 1].set_ylabel('Accuracy/ Loss')\n",
    "\n",
    "ax[1, 0].plot(rNet1_history.history['Accuracy'])\n",
    "ax[1, 0].plot(rNet1_history.history['val_Accuracy'])\n",
    "ax[1, 0].plot(rNet1_history.history['loss'])\n",
    "ax[1, 0].plot(rNet1_history.history['val_loss'])\n",
    "ax[1, 0].set_title('ResNet Model')\n",
    "ax[1, 0].set_xlabel('Epochs')\n",
    "ax[1, 0].set_ylabel('Accuracy/ Loss')\n",
    "\n",
    "ax[1, 1].plot(vgg_history['Accuracy'])\n",
    "ax[1, 1].plot(vgg_history['val_Accuracy'])\n",
    "ax[1, 1].plot(vgg_history['loss'])\n",
    "ax[1, 1].plot(vgg_history['val_loss'])\n",
    "ax[1, 1].set_title('VGG Model')\n",
    "ax[1, 1].set_xlabel('Epochs')\n",
    "ax[1, 1].set_ylabel('Accuracy/ Loss')\n",
    "\n",
    "fig.legend(bbox_to_anchor=(0.25, 0), loc=2, ncol=2)\n",
    "plt.yticks(np.arange(0, 1, step=0.1))\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bcdd480fa988c0bff1942a543d37a5a4859f7f33e82c1f9135f65e6471dc1f87"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ai')",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
